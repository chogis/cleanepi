---
title: "cleanepi"
output: 
  rmarkdown::html_vignette:
    df_print: "kable"
vignette: >
  %\VignetteIndexEntry{cleanepi}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE} 
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", eval = FALSE,
                      fig.width = 7, fig.height = 7, fig.align = "center")
```


## An overview

No matter how many measures are taken, one must always expect  messy data from the real-world, with duplicates, errors, incomplete,  or  irrelevant formats. Data cleaning is an essential step in data analysis. It allows to produce accurate, reliable and reproducible results. However, data cleaning is a significant barrier in data analysis because it takes a long time to complete. 

**cleanepi** is an R package to clean, curate, and standardize epidemiological data. It contains functions to perform several data cleaning tasks that an end-user would anticipate to be performed on a cluttered dataset. 

**cleanepi** is specifically designed for epidemiological data, and works with data frame-like data structure. This vignette provides a detailed description the functions included in the package and how to use them. 

```{r setup}
library(cleanepi)
```

## General data cleaning tasks

The main function in **cleanepi** is `clean_data()` that can perform the following tasks:

1.  Clean up column names and convert them to more sensible formats. This includes many sub-tasks such as changing a space, dot, or hyphen between two words with underscore; converting camel-cases to snake-cases; substituting foreign characters with their corresponding English characters; and splitting a long word into multiple short words by capital characters within, if any, and connecting them with underscores.   
2. Remove empty rows and columns.   
3. Remove constant columns, i.e. columns with the same value across all rows.   
4. Replace missing entries with `NA`.   
5. Remove duplicated rows (across all columns or some specific columns).   
6. Convert character columns into date if the column actually contains values of type `Date` to some extent (default is 50% of the values are `Date`).
7. Detect and remove rows with subject IDs that do not comply with the expected format.

The function `clean_data()` returns a `list` of 2 objects:\
1. a `data.frame` or `linelist` object with the cleaned data.\
2. a `list` of reports from all the actions performed on the given dataset.


```{r eval=FALSE}
# IMPORTING THE TEST DATASET
test_data <- readRDS(system.file("extdata", "test_df.RDS",
                                 package = "cleanepi"))

# DEFINING THE DATA CLEANING PARAMETERS
params <- list(
  remove_duplicates = TRUE,
  target_columns = NULL,
  replace_missing = TRUE,
  na_comes_as = "-99",
  check_timeframe = TRUE,
  timeframe = as.Date(c("1973-05-29", "2023-05-29")),
  error_tolerance = 0.5,
  subject_id_col_name = "study_id",
  subject_id_format = "PS000P2",
  prefix = "PS",
  suffix = "P2",
  range = c(1, 100)
  )

# CLEAN THE INPUT DATA FRAME
res <- clean_data(
  data = test_data,
  params = params
)

cleaned_data <- res$data
cleaning_report <- res$report
```

## Specific data cleaning tasks

Data cleaning operations such as renaming columns; removing empty rows, columns, and  columns with a constant value;  and standardization of date columns  are automatically applied to the input data. We consider them as the `implicit data cleaning steps` and will be executed by default.   The user can also call each data cleaning function individually to perform a specific  task. 

### Detect and remove incorrect subject IDs

The `check_subject_ids()` function  detects and  removes rows of the input dataset where the subject ID does not match the expected format. 
The function requires the following parameters:   

1. `data`: the input dataset (required)   
2. `id_column_name`: The name of the column with the subject IDs (required)  
3. `format`: the expected subject IDs format (required)   
4. `prefix`: the expected prefix in the subject IDs (optional)   
5. `suffix`: the expected suffix in the subject IDs (optional)   
6. `range`: the expected range of numbers in the subject IDs (optional)   
7. `remove`: a Boolean variable and default is `FALSE`. If `TRUE`, rows with incorrect subject IDs will be removed.    
8. `verbose`: a Boolean variable and default is `FALSE`. If `TRUE`, a message will be printed along the execution of the function. 
9. `report`: a `list` containing reports for other data cleaning tasks  **cleanepi** (optional).

The function returns a `list` of 2 elements:    

* Clean input dataset where rows with bad IDs were removed (`if remove = TRUE`) or not.
* A `list`, or augmented  report list,   with an element named as `incorrect_subject_id` and  rows that have incorrect subject IDs as it value.    

```{r eval=FALSE}
# DETECT INCORRECT SUBJECT IDs
dat <- check_subject_ids(
 data = readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi")),
 id_column_name = "study_id",
 format = "PS000P2",
 prefix = "PS",
 suffix = "P2",
 range = c(1, 100),
 remove = FALSE,
 verbose = TRUE,
 report = list()
 )

# DISPLAY ROWS WITH THE INCORRECT SUBJECT IDs
dat$report

# DETECT AND REMOVE INCORRECT SUBJECT IDs
dat <- check_subject_ids(
 data = readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi")),
 id_column_name = "study_id",
 format = "PS000P2",
 prefix = "PS",
 suffix = "P2",
 range = c(1, 100),
 remove = TRUE,
 verbose = FALSE,
 report = list()
 )
```


### Calculate age

The `calculate_age()` function calculates  ages of individuals (in years, months, weeks, and) days for a given date column and reference date. It takes the following arguments:  

1. `data`: the input dataset (required)
2. `date_column_name`: the name of the column to which the age is calculated for (required) 
3. `end_date`: the reference date to which the age is calculated from 
4. `age_in`: the age unit (years, months, weeks, or days) and default is years (optional)

This function returns the input dataset with 1 or 2 columns that contains, respectively: the calculated age in the specified unit and the remaining number of days.  

```{r eval=FALSE}
# CALCULATE INDIVIDUAL AGE FROM THE `dateOfBirth` COLUMN
age <- calculate_age(
 data = readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi")),
 date_column_name = "dateOfBirth",
 end_date = Sys.Date(),
 age_in = "months"
 )

## DISPLAY THE OUTPUT OBJECT
head(age)  # note the last 2 columns
```


### Check date sequence
The `check_date_sequence()` function checks the order of sequences in date columns and makes sure the values in all rows comply with the desired order. For example,  the values in `date_of_infection`, `date_of_admission`, and `date_of_death` columns should be in the order they are listed here. Any row where the values are not in this order will be considered as wrong and eventually be removed by the `check_date_sequence()` function. The function takes the following arguments:  

1. `data`: the input dataset
2. `event_cols`: a `vector` with the names of  date columns of interest. These should be listed in the expected order of occurrence, and would look like this for the mentioned example above: `event_cols = c("date_of_infection", "date_of_admission", "date_of_death"`
3. `remove_bad_seq`: a Boolean variable and the default value is `false`. If `TRUE`, rows with incorrect date sequence will be deleted from the output object. Otherwise, they will be detected and stored in the report object.    
4. `report`: a `list` containing reports for other data cleaning tasks  **cleanepi** (optional).

The function returns the input dataset without the incorrect rows (if `remove_bad_seq = TRUE`) and a `list` containing the details about the   incorrect date sequences.    

```{r eval=FALSE}
# DETECT ROWS WITH INCORRECT DATE SEQUENCE
good_date_sequence <- check_date_sequence(
 data = readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi")),
 event_cols = c("date_first_pcr_positive_test", "date.of.admission"),
 remove_bad_seq = FALSE,
 report = list()
 )

# PRINT ROWS WITH INCORRECT DATE SEQUENCE
good_date_sequence$report
```


### Find duplicated rows

The `find_duplicates()` function can be used to identify duplicated rows from an input dataset. The function takes the following arguments:   

1. `data`: the input dataset
2. `target_columns`: a `vector` of column names or indexes from which duplicated rows will be identified. If `NULL`, duplicates will be detected across all columns. If the input dataset is a `linelist` object, this can be set to `tags` to identify duplicates across the **tagged variables** only.

The function returns all duplicated rows in the dataset based on all or the specified columns. Two extra columns: `row_id` and `group_id` will be added to the dataset, to represent, respectively, the row numbers of the duplicated rows from the input dataset and the duplicated group ID assigned to them, every group being the same set of values in the columns of interest. 

```{r eval=FALSE}
# FIND DUPLICATES
dups <- find_duplicates(
  data = readRDS(system.file("extdata", "test_linelist.RDS",
                             package = "cleanepi")),
  target_columns = "tags"
)

# VISUALIZE THE DUPLICATES
head(dups) # note the first 2 columns
```


### Remove duplicates

To remove duplicated rows, use the `remove_duplicates()` function. It internally calls the `find_duplicates()` function. It expects the following parameters:  

1. `data`: the input dataset
2. `target_columns`: a `vector` of column names or indexes from which duplicated rows will be identified. If `NULL`, duplicates will be detected across all columns. f the input dataset is a `linelist` object, this can be set to `tags` to identify duplicates across the **tagged variables** only.
3. `remove`: a `numeric vector` of the indices of the duplicated rows to be removed. If `NULL`, duplicates will be removed and only the first occurrence of the duplicated rows will be kept.
4. `report`: a `list` containing reports for other data cleaning tasks  **cleanepi** (optional).   

The function returns the inputs dataset without the duplicated rows and a `list` with the outcomes from the duplicates removal operation. This is in turn a list of 3 elements:  

* `all_dups`: this is the subset input dataset with all the duplicated rows detected using the `find_duplicates()` function    
* `removed_dups`: a subset of the input dataset that was removed
* `duplicates_checked_from`: a comma-separated string of column names that were used to identify the duplicated rows.

```{r eval=FALSE}
# REMOVE DUPLICATES ACROSS TAGGED VARIABLES (KEEP ONLY THE FIRST OCCURENCE OF
# THE DUPLICATED ROWS)
no_dups <- remove_duplicates(
  data = readRDS(system.file("extdata", "test_linelist.RDS",
                             package = "cleanepi")),
  target_columns = "tags",
  remove = NULL,
  report = list()
)

# DETECT DUPLICATES FROM TAGGED COLUMNS
dups <- find_duplicates(
  data = readRDS(system.file("extdata", "test_linelist.RDS",
                             package = "cleanepi")),
  target_columns = "tags"
)

# REMOVE FIRST OCCURRENCE OF DUPLICATED ROWS
dups_index_to_remove <- dups$row_id[seq(1, nrow(dups), 2)]
no_dups <- remove_duplicates(
  data = readRDS(system.file("extdata", "test_linelist.RDS",
                             package = "cleanepi")),
  target_columns = "tags",
  remove = dups_index_to_remove,
  report = list()
)
```
